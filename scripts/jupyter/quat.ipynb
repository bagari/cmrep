{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e08d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba62cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_q(r, v, dtype=torch.float64, device='cpu'):\n",
    "    return torch.tensor(r, dtype=dtype, device=device), torch.tensor(v, dtype=dtype, device=device)\n",
    "\n",
    "def point_to_q(v):\n",
    "    return torch.tensor(0, dtype=v.dtype, device=v.device), v\n",
    "\n",
    "def q_norm(q):\n",
    "    r, v = q\n",
    "    return torch.sqrt(r * r + torch.dot(v, v))\n",
    "\n",
    "def q_normalize(q):\n",
    "    r, v = q\n",
    "    norm = torch.sqrt(r * r + torch.dot(v, v))\n",
    "    return (r/norm, v/norm)\n",
    "\n",
    "def q_conj(q):\n",
    "    r, v = q\n",
    "    return (r, -v)\n",
    "\n",
    "def q_add(q1, q2):\n",
    "    r1, v1 = q1\n",
    "    r2, v2 = q2\n",
    "    return r1+r2, v1+v2\n",
    "\n",
    "def q_mul(q1, q2):\n",
    "    r1, v1 = q1\n",
    "    r2, v2 = q2\n",
    "    return r1 * r2 - torch.dot(v1, v2), v1 * r2 + r1 * v2 + torch.cross(v1, v2)\n",
    "\n",
    "def q_scale(q, a):\n",
    "    r, v = q\n",
    "    return (a * r, a * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "811bc932",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = make_q(np.random.randn(), np.random.randn(3))\n",
    "q2 = make_q(np.random.randn(), np.random.randn(3))\n",
    "p = make_q(0, np.random.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92c18c",
   "metadata": {},
   "source": [
    "Check that rotating using a norm-1 quaternion and multiplying by alpha^2 is the same as rotating by norm alpha quaternion. This means that to perform similarity transforms, we don't need to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52b2b92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.7593, dtype=torch.float64), tensor(0.8018, dtype=torch.float64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_norm(q1), q_norm(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "faf2e407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.1633e-17, dtype=torch.float64),\n",
       " tensor([ 1.3740, -0.9602,  1.8300], dtype=torch.float64))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = q_mul(q_mul(q1, p), q_conj(q1))\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edd3fa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.1813e-16, dtype=torch.float64),\n",
       " tensor([ 1.3740, -0.9602,  1.8300], dtype=torch.float64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1n = q_normalize(q1)\n",
    "p2 = q_mul(q_mul(q1n, p), q_conj(q1n))\n",
    "tuple(u * q_norm(q1)**2 for u in p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4628d",
   "metadata": {},
   "source": [
    "Check the Jacobian of quaternion rotation and translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46aacd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center of rotation\n",
    "C = make_q(0, np.random.randn(3))[1]\n",
    "\n",
    "# Diameter (scaling)\n",
    "diam = 3.1535\n",
    "\n",
    "# Offset\n",
    "b = make_q(0, np.random.randn(3))[1].requires_grad_(True)\n",
    "\n",
    "# Quaternion\n",
    "q = tuple(u.clone().detach().requires_grad_(True) for u in q1)\n",
    "\n",
    "# Starting point\n",
    "A = make_q(0, np.random.randn(3))[1]\n",
    "\n",
    "# Transformed point p\n",
    "A0 = point_to_q(A-C)\n",
    "B0 = q_mul(q_mul(q, A0), q_conj(q))\n",
    "B = B0[1] + C + b * diam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f699b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.0061, dtype=torch.float64),\n",
       " tensor([-2.4960, -2.2834,  3.8022], dtype=torch.float64),\n",
       " tensor([ 1.0407,  1.3245, -1.3560], dtype=torch.float64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch derivatives\n",
    "gamma = make_q(0, [0.33, 0.42, -0.43])[1]\n",
    "B.backward(gamma)\n",
    "q[0].grad, q[1].grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4cd0c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([ 1.0407,  1.3245, -1.3560], dtype=torch.float64) vs tensor([ 1.0407,  1.3245, -1.3560], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(-3.0061, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor([-2.4960, -2.2834,  3.8022], dtype=torch.float64,\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerical derivatives. For b it is just gamma\n",
    "print(f'b: {b.grad} vs {gamma * diam}')\n",
    "\n",
    "# Compute the derivative for q\n",
    "G = point_to_q(gamma)\n",
    "t1 = q_mul(q_mul(G, q), q_conj(A0))\n",
    "t2 = t1\n",
    "q_add(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bad2b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2, 5) (0, 2, 5)\n",
      "(0, 2, 5) (1, 2, 4)\n",
      "(1, 2, 4) (0, 2, 5)\n",
      "(1, 2, 4) (1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "allq = [G, q_conj(G), q, q_conj(q), A0, q_conj(A0)]\n",
    "all_comb = []\n",
    "for p1 in range(6):\n",
    "    for p2 in range(6):\n",
    "        for p3 in range(6):\n",
    "            all_comb.append( ((p1,p2,p3), q_mul(q_mul(allq[p1], allq[p2]), allq[p3]))) \n",
    "            \n",
    "for i1, (idx1, u1) in enumerate(all_comb):\n",
    "    for i2, (idx2, u2) in enumerate(all_comb):\n",
    "        qsum = q_add(u1, u2)\n",
    "        dr = (qsum[0]-q[0].grad).detach().cpu().numpy() ** 2\n",
    "        dv = np.sum((qsum[1]-q[1].grad).detach().cpu().numpy() ** 2)\n",
    "        if dr + dv < 1e-6:\n",
    "            print(idx1, idx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a2c22",
   "metadata": {},
   "source": [
    "What is the derivative of quaternion product $q(0,x){\\overline q}$ with respect to $x$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51ea89fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num:  [-0.01942954 -0.74520771  1.98720333]\n",
      "Anl:  [-0.01942954 -0.74520771  1.98720333]\n"
     ]
    }
   ],
   "source": [
    "# This is the numerical derivative\n",
    "X = torch.tensor(np.random.randn(3), requires_grad=True)\n",
    "fX = q_mul(q_mul(q, point_to_q(X)), q_conj(q))\n",
    "fX[1].backward(gamma)\n",
    "print('Num: ', X.grad.detach().cpu().numpy())\n",
    "\n",
    "# Figure out the analytical derivative\n",
    "dX = q_mul(q_mul(q_conj(q), point_to_q(gamma)), q)[1]\n",
    "print('Anl: ', dX.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae80c52",
   "metadata": {},
   "source": [
    "Inverse rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa58aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_point(q, b, C, A, diam):\n",
    "    A0 = point_to_q(A-C)\n",
    "    B0 = q_mul(q_mul(q, A0), q_conj(q))\n",
    "    return B0[1] + C + b * diam\n",
    "\n",
    "def transform_point_inv(q, b, C, B, diam):\n",
    "    B0 = point_to_q(B - C - b * diam)\n",
    "    # A0 = q_scale(q_mul(q_mul(q_conj(q), B0), q), 1.0 / q_norm(q)**4)\n",
    "    A0 = q_scale(q_mul(q_mul(q_conj(q), B0), q), 1.0 / q_norm(q)**4)\n",
    "    return A0[1] + C\n",
    "\n",
    "def transform_point_inv_nonorm(q, b, C, B):\n",
    "    B0 = point_to_q(B - C - b)\n",
    "    A0 = q_mul(q_mul(q_conj(q), B0), q)\n",
    "    return A0[1] + C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d310c61",
   "metadata": {},
   "source": [
    "Now, I would like to backprop through the inverse transform, i.e., if I have some function f(A) of A, where A is transform_point_inv(q, b, C, B), then what is D_B f?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a73ddd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  4.0246e-16, -2.2204e-16], dtype=torch.float64,\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_point_inv(q, b, C, transform_point(q, b, C, A, diam), diam) - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "552a36b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2982, -0.0921,  1.2573], dtype=torch.float64,\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_point_inv(q, b, C, B, diam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5aae1",
   "metadata": {},
   "source": [
    "Here are the parameters of the inverse transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a4562e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2982, -0.0921,  1.2573], dtype=torch.float64,\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_inv = q_scale(q_conj(q), 1.0 / q_norm(q)**2)\n",
    "b_inv = q_mul(q_mul(q_inv, point_to_q(-b)), q_conj(q_inv))[1]\n",
    "transform_point(q_inv, b_inv, C, B, diam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1069cdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.0061, dtype=torch.float64),\n",
       " tensor([-2.4960, -2.2834,  3.8022], dtype=torch.float64),\n",
       " tensor([ 1.0407,  1.3245, -1.3560], dtype=torch.float64))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0].grad.zero_()\n",
    "q[1].grad.zero_()\n",
    "b.grad.zero_()\n",
    "fA = transform_point(q, b, C, A, diam)\n",
    "fA.backward(gamma)\n",
    "q[0].grad, q[1].grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "402c209a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.4662, dtype=torch.float64),\n",
       " tensor([ 0.1462, -0.1114,  0.2236], dtype=torch.float64),\n",
       " tensor([ 0.0948,  0.1548, -0.6746], dtype=torch.float64))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0].grad.zero_()\n",
    "q[1].grad.zero_()\n",
    "b.grad.zero_()\n",
    "gA = transform_point_inv(q, b, C, A, diam)\n",
    "gA.backward(gamma)\n",
    "q[0].grad, q[1].grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f6dc365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(-0.4662, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       "  tensor([ 0.1462, -0.1114,  0.2236], dtype=torch.float64,\n",
       "         grad_fn=<AddBackward0>)),\n",
       " tensor([ 0.0948,  0.1548, -0.6746], dtype=torch.float64,\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the b gradient, it is correct\n",
    "grad_finv_b = -q_mul(q_mul(q, point_to_q(gamma)), q_conj(q))[1] * (diam / q_norm(q)**4)\n",
    "\n",
    "# And this is the q gradient\n",
    "grad_finv_q = q_add(\n",
    "    q_scale(q_mul(q_mul(point_to_q(A - C - b * diam), q), q_conj(G)), 2 / q_norm(q)**4),\n",
    "    q_scale(q, -4 * torch.dot(q_mul(q_mul(q_conj(q), point_to_q(A - C - b * diam)), q)[1], gamma) / q_norm(q)**6))\n",
    "\n",
    "grad_finv_q, grad_finv_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e05922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
